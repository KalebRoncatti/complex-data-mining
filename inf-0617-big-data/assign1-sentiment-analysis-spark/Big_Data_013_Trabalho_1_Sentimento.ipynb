{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kroncatti/complex-data-mining/blob/master/inf-0617-big-data/assign1-sentiment-analysis-spark/Big_Data_013_Trabalho_1_Sentimento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integrantes do grupo:\n",
        "\n",
        "- Kaleb Roncatti de Souza\n",
        "- Nelson Gomes Brasil Junior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJquc_EOk0rY"
      },
      "source": [
        "**Instruções iniciais**\n",
        "\n",
        "*   Abra os links dos dados: \n",
        "    * https://tinyurl.com/bd-friends\n",
        "*   Clique em \"Adicionar atalho ao Drive\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "parQVI_aEvHi"
      },
      "source": [
        "# Solução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvqjY2c7GkTz",
        "outputId": "edd4fced-be03-4ca6-b573-118a9103c3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQxqkJ4kE1ha",
        "outputId": "32ec0ad8-45ee-4c74-ace3-87849c3a8310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Collecting twython\n",
            "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from twython) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from twython) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.2.2)\n",
            "Installing collected packages: twython\n",
            "Successfully installed twython-3.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk twython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7clpACSPE4hs",
        "outputId": "210e712e-2445-47ef-9e71-ee10cfbf02e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "!python -m nltk.downloader vader_lexicon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGC-3wxv7Rbp",
        "outputId": "7386b6c6-1a80-4087-d6af-cc430d6bdab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 48 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 48.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845513 sha256=7893a6d4142fdf5a4593da0a1bcee2ed6ac9a9cf83177a181ac4b354192b5381\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark, findspark\n",
            "Successfully installed findspark-2.0.1 py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.2.2/spark-3.2.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.2-bin-hadoop3.2.tgz\n",
        "!pip install findspark pyspark "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wA12VdZ7nil",
        "outputId": "27108902-4d2b-4e2b-a27b-ac96ed73cfb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTHONHASHSEED=1234\n",
            "env: JAVA_HOME=/usr/lib/jvm/default-java\n",
            "env: SPARK_HOME=/content/spark-3.2.2-bin-hadoop3.2\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONHASHSEED=1234\n",
        "%env JAVA_HOME=/usr/lib/jvm/default-java\n",
        "%env SPARK_HOME=/content/spark-3.2.2-bin-hadoop3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4WyUbr9G7pOW"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init(\"/content/spark-3.2.2-bin-hadoop3.2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XOi6nUq-7spA"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "appName = 'Big Data'\n",
        "master = 'local[*]'\n",
        "\n",
        "spark = SparkSession.builder     \\\n",
        "    .master(master) \\\n",
        "    .appName(appName) \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "j8FV0Qhx7s5a"
      },
      "outputs": [],
      "source": [
        "input_data = spark.sparkContext.textFile('file:///content/drive/My Drive/friends')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "BdDT9KZs75Ii"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "sentiment = SentimentIntensityAnalyzer()\n",
        "characters = ['monica', 'chandler', 'ross', 'rachel', 'joey', 'phoebe', \n",
        "              'gunther', 'janice', 'richard', 'emily']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7xrl1k_GggD",
        "outputId": "ba7fe228-b1c6-49ff-838d-15d97a824826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1001 - The One After Joey And Rachel Kiss', 'Written by: Andrew Reich & Ted Cohen', 'Transcribed by: Coffee Mug', '', \"[Scene: Barbados, Monica and Chandler's Room. They both enter from Ross's room. Monica still has her big, frizzy hair.]\", '', 'Monica: Oh, the way you crushed Mike at ping pong was such a turn-on.You wanna...? (plays with her finger on Chandlers chest)', '', \"Chandler: You know, I'd love to, but I'm a little tired.\", '']\n",
            "Total of records : 140563\n",
            "Number of partitions: 227\n"
          ]
        }
      ],
      "source": [
        "print(input_data.take(10))\n",
        "log = f\"Total of records : {input_data.count()}\"\n",
        "print(log)\n",
        "log = f\"Number of partitions: {input_data.getNumPartitions()}\"\n",
        "print(log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "KRdb5Xsp8CZj"
      },
      "outputs": [],
      "source": [
        "def line_sentiment(line):\n",
        "  line = line.lower()\n",
        "  try:\n",
        "    character, phrase = line.split(':', 1)\n",
        "    # Checking if the current character is on our list\n",
        "    if character in characters:\n",
        "      # Returning (Key, (Polarity, 1))\n",
        "      yield(character, (float(sentiment.polarity_scores(phrase)[\"compound\"]), 1))\n",
        "\n",
        "  except Exception as e:\n",
        "    # In a real case scenario, we would most probably try to check what we are ignoring\n",
        "    pass\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "t28-0AL78Um8"
      },
      "outputs": [],
      "source": [
        "s = input_data.flatMap(line_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjs8C50G8gUt",
        "outputId": "9c6a3e1d-578c-4fe0-9c9e-14e58e5d7998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('monica', (-0.4215, 1)), ('chandler', (-0.2048, 1)), ('monica', (0.0, 1)), ('chandler', (0.0, 1)), ('phoebe', (0.0, 1)), ('monica', (0.0, 1)), ('phoebe', (0.2023, 1)), ('ross', (0.0, 1)), ('phoebe', (0.0, 1)), ('monica', (-0.296, 1))]\n",
            "Key: monica\n",
            "Value: (-0.4215, 1)\n"
          ]
        }
      ],
      "source": [
        "# Checking the data\n",
        "print(s.take(10))\n",
        "sample = s.take(1) \n",
        "print(f\"Key: {sample[0][0]}\")\n",
        "print(f\"Value: {sample[0][1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwdv0ruWd21o",
        "outputId": "24f174a1-6bc9-4d17-cd69-49c63edd54ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Sum Polarity: [('gunther', (12.057499999999997, 132)), ('emily', (21.3578, 167)), ('janice', (36.08109999999999, 211)), ('chandler', (1038.7343999999996, 8386)), ('joey', (1071.1549000000005, 8227)), ('richard', (29.971700000000002, 254)), ('monica', (978.2027000000004, 8325)), ('phoebe', (1071.3556999999998, 7365)), ('ross', (1214.3541999999998, 9165)), ('rachel', (1342.4143999999997, 9147))]\n"
          ]
        }
      ],
      "source": [
        "# Implemente e aplique um método reduce para acumulação dos sentimentos dos personagens\n",
        "def reduce_acc(acc, value) :\n",
        "  polarity_acc = acc[0]\n",
        "  count_acc = acc[1]\n",
        "  polarity_v = value[0]\n",
        "  count_v = value[1]\n",
        "  return(polarity_acc + polarity_v, count_acc + count_v)\n",
        "\n",
        "total = s.reduceByKey(reduce_acc)\n",
        "print(f\"Total Sum Polarity: {total.take(10)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHpV8nOzd_Rv",
        "outputId": "cd4503a8-114b-4cff-c8e8-6d6404c354ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('gunther', 0.09134), ('emily', 0.12789), ('janice', 0.171), ('chandler', 0.12387), ('joey', 0.1302), ('richard', 0.118), ('monica', 0.1175), ('phoebe', 0.14547), ('ross', 0.1325), ('rachel', 0.14676)]\n"
          ]
        }
      ],
      "source": [
        "# Implemente e aplique um método para calculo do sentimento médio\n",
        "def average(value):\n",
        "  sum = value[0]\n",
        "  count = value[1]\n",
        "  return(round(sum/count, 5))\n",
        "\n",
        "avg = total.mapValues(average)\n",
        "print(avg.take(10))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "12818feda82480bac11e7c8601372f8f0ffe4e39b3f7b5744e40d3d6a8b5428b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
