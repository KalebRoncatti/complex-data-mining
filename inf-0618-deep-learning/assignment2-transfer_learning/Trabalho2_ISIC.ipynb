{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nhShPYviZBl"
      },
      "source": [
        "# Trabalho 2: Transfer Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY17j0sUicN-"
      },
      "source": [
        "## Carregamento dos dados\n",
        "\n",
        "Os .zips contendo o dataset está no google drive. O código abaixo faz o download, e extrai o zip. Note que você precisará logar no Google para que esse processo seja possível. Caso haja alguma falha ou erro no processo, reinicie o notebook, e tente novamente.\n",
        "\n",
        "Depois desse processo, teremos no diretório:\n",
        "\n",
        "*   isic2017-train: 2000 imagens. \n",
        "*   isic2017-val: 150 imagens.\n",
        "*   isic2017-test: 650 imagens.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWLEGyXxBxv4"
      },
      "source": [
        "!pip install PyDrive &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovqt0wIlCOQM"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1EH2tlRi4Iqq8WfLOXl6hMc5jTeiIRzaW\"})\n",
        "downloaded.GetContentFile('isic2017-trainval.zip')\n",
        "!unzip -q isic2017-trainval.zip\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1uP1tCj6-T2FXxk7g7gqoC_SGOhqIQyrM\"})   \n",
        "downloaded.GetContentFile('isic2017-test.zip')       \n",
        "!unzip -q isic2017-test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KytaD17V41aR",
        "outputId": "3d5254b6-d643-43f1-8fa1-501e55b7f235"
      },
      "source": [
        "!ls -1 isic2017-train/malignant | wc -l "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIOR7s4hjYxU"
      },
      "source": [
        "Em cada diretório, temos uma pasta contendo as lesões benignas ('/benign') e outra contendo as lesões malignas ('/malignant'). A separação dessa forma facilita a importação dos dados utilizando o keras.\n",
        "Estude o uso da ImageDataGenerator do Keras, pois ela facilita o uso de aumentação e pré-processamento dos dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frcOKiwUKN_C",
        "outputId": "e3c35946-9821-453f-86a2-d88059a7fd0e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=45)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'isic2017-train/',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        'isic2017-val/',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 150 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOt9KOoAWg5a"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,training_data,validation_data):\n",
        "        # training\n",
        "        batch_index = 0\n",
        "        while batch_index <= training_data.batch_index:\n",
        "            img, label = training_data.next()\n",
        "            if batch_index ==0:\n",
        "              img_list = img\n",
        "              label_list = label\n",
        "            else:\n",
        "              img_list = np.concatenate((img_list, img), axis=0)\n",
        "              label_list = np.concatenate((label_list, label), axis=0)\n",
        "            batch_index = batch_index + 1\n",
        "        self.x = img_list\n",
        "        self.y = label_list\n",
        "\n",
        "        # validation\n",
        "        batch_index = 0\n",
        "        while batch_index <= validation_data.batch_index:\n",
        "            img, label = validation_data.next()\n",
        "            if batch_index ==0:\n",
        "              img_list = img\n",
        "              label_list = label\n",
        "            else:\n",
        "              img_list = np.concatenate((img_list, img), axis=0)\n",
        "              label_list = np.concatenate((label_list, label), axis=0)\n",
        "            batch_index = batch_index + 1\n",
        "        self.x_val = img_list\n",
        "        self.y_val = label_list\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        y_pred_train = self.model.predict(self.x)\n",
        "        print(\"SHAPE\", y_pred_train.shape)\n",
        "        roc_train = roc_auc_score(self.y[:,1], y_pred_train[:,1])\n",
        "        y_pred_val = self.model.predict(self.x_val)\n",
        "        roc_val = roc_auc_score(self.y_val[:,1], y_pred_val[:,1])\n",
        "        logs[\"train_auc\"] = roc_train\n",
        "        logs[\"val_auc\"] = roc_val\n",
        "        keys = list(logs.keys())\n",
        "        print('\\rroc-auc_train: %s - roc-auc_val: %s' % (str(round(roc_train,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
        "        return\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc8C7f-T9gST"
      },
      "source": [
        "## Treine e avalie o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6cGb53WVt97"
      },
      "source": [
        "roc = RocCallback(training_data=train_generator,\n",
        "                  validation_data=validation_generator)\n",
        "# Para verificar a AUC depois de cada época, inclua 'roc' em callbacks do método fit.\n",
        "# Exemplo:\n",
        "#history = model.fit(train_generator, epochs=50, callbacks=[roc], validation_data=validation_generator)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}